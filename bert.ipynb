{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cp1YRVQRrsjI",
    "outputId": "699babb3-56c1-4c4b-b488-10044b0a8860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.19.3.tar.gz (25.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2 MB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow==2.1.0\n",
      "  Using cached tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl (120.8 MB)\n",
      "Requirement already satisfied: scipy==1.4.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (1.4.1)\n",
      "Collecting scikit-learn==0.21.3\n",
      "  Using cached scikit_learn-0.21.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.5 MB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (3.1.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (1.0.3)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-0.2.5-py3-none-any.whl (12 kB)\n",
      "Collecting keras_bert>=0.81.0\n",
      "  Downloading keras-bert-0.86.0.tar.gz (26 kB)\n",
      "Requirement already satisfied: requests in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (2.23.0)\n",
      "Requirement already satisfied: joblib in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (0.14.1)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cchardet==2.1.5\n",
      "  Downloading cchardet-2.1.5.tar.gz (653 kB)\n",
      "\u001b[K     |████████████████████████████████| 653 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (2.4)\n",
      "Requirement already satisfied: bokeh in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (2.0.1)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-0.0.12.tar.gz (21 kB)\n",
      "Requirement already satisfied: packaging in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (20.3)\n",
      "Requirement already satisfied: tensorflow_datasets in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (2.0.0)\n",
      "Collecting transformers>=2.11.0\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "\u001b[K     |████████████████████████████████| 769 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ktrain) (7.13.0)\n",
      "Collecting syntok\n",
      "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[K     |████████████████████████████████| 468 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shap\n",
      "  Downloading shap-0.35.0.tar.gz (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
      "Processing /Users/mv96/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp37-none-any.whl\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (1.28.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (3.11.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.1.0->ktrain) (3.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.0.1->ktrain) (2019.3)\n",
      "Collecting Keras>=2.4.3\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting keras-transformer>=0.38.0\n",
      "  Downloading keras-transformer-0.38.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from requests->ktrain) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from requests->ktrain) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from requests->ktrain) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from bokeh->ktrain) (5.3.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from bokeh->ktrain) (2.11.1)\n",
      "Requirement already satisfied: tornado>=5 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from bokeh->ktrain) (6.0.4)\n",
      "Requirement already satisfied: pillow>=4.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from bokeh->ktrain) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from bokeh->ktrain) (3.7.4.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets->ktrain) (0.21.1)\n",
      "Requirement already satisfied: tqdm in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets->ktrain) (4.44.1)\n",
      "Requirement already satisfied: future in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets->ktrain) (0.18.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets->ktrain) (19.3.0)\n",
      "Requirement already satisfied: promise in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets->ktrain) (2.3)\n",
      "Requirement already satisfied: dill in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow_datasets->ktrain) (0.3.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-macosx_10_10_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.7.14.tar.gz (690 kB)\n",
      "\u001b[K     |████████████████████████████████| 690 kB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from transformers>=2.11.0->ktrain) (3.0.12)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (3.0.4)\n",
      "Requirement already satisfied: pickleshare in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (0.7.5)\n",
      "Requirement already satisfied: pygments in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (46.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (0.15.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (4.8.0)\n",
      "Requirement already satisfied: backcall in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (0.1.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (4.3.3)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from ipython->ktrain) (0.1.0)\n",
      "Requirement already satisfied: h5py in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.14.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.2)\n",
      "Collecting keras-pos-embd>=0.11.0\n",
      "  Downloading keras-pos-embd-0.11.0.tar.gz (5.9 kB)\n",
      "Collecting keras-multi-head>=0.27.0\n",
      "  Downloading keras-multi-head-0.27.0.tar.gz (14 kB)\n",
      "Collecting keras-layer-normalization>=0.14.0\n",
      "  Downloading keras-layer-normalization-0.14.0.tar.gz (4.3 kB)\n",
      "Collecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading keras-position-wise-feed-forward-0.6.0.tar.gz (4.4 kB)\n",
      "Collecting keras-embed-sim>=0.8.0\n",
      "  Downloading keras-embed-sim-0.8.0.tar.gz (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow_datasets->ktrain) (1.51.0)\n",
      "Requirement already satisfied: click in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers>=2.11.0->ktrain) (7.1.1)\n",
      "Requirement already satisfied: wcwidth in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.1.9)\n",
      "Requirement already satisfied: parso>=0.5.2 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->ktrain) (0.5.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.6.0)\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mv96/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
      "Building wheels for collected packages: ktrain, keras-bert, langdetect, jieba, cchardet, seqeval, syntok, shap, keras-transformer, regex, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.19.3-py3-none-any.whl size=25267700 sha256=e7b8285540c41c4c2f5c35fc875d51d2801b8697ceecbe90745d92529e1910d6\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/ae/36/35/71679da201610a706e49ce45a0ce7baa6f142d65adc080f74a\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-bert: filename=keras_bert-0.86.0-py3-none-any.whl size=34147 sha256=56951ffc23d51d8557ceb6b5e580579108bbdf7d6a2a7f922399b059d62d407c\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/fc/c1/0a/eb9187261b3f192ac314aefb54fe66f50540c3edb906599633\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=23182a4af832fb292e8436769599aaa2d598a813cea9f8c837783c71ebdb700d\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/59/f6/9d/85068904dba861c0b9af74e286265a08da438748ee5ae56067\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=4c6c5adede428c554f7ef452f4af7b078cd1ac87fa55d507aa2754414566ca52\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/24/aa/17/5bc7c72e9a37990a9620cc3aad0acad1564dcff6dbc2359de3\n",
      "  Building wheel for cchardet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cchardet: filename=cchardet-2.1.5-cp37-cp37m-macosx_10_9_x86_64.whl size=124151 sha256=18ad9947a1eb045d2dc6c97aabe5eca40f306c470a06a4cc3630c1850958d776\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/03/17/fa/b49a66aad9a14989c34ebef6fbdfe8ee97abfdefc08a08b063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=de9e0be50c7beaeae88b1dd9a011d867be8e2cc724ae490f57bed4ab7aa56574\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\n",
      "  Building wheel for syntok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20916 sha256=7a0f4c7fbc42f1365b9e8c48a3ecd9176a3d958708cbf5bf7ca4f8ed1b4add1d\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.35.0-cp37-cp37m-macosx_10_9_x86_64.whl size=310377 sha256=011f1d2e2faf93bc99d377c2d9bcafbe727854ccbaaa5d8873457fbac8eecc9d\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/c3/e0/82/26cebc699e23c6a1b9963981e1a10ed7de75db012f4af12428\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-py3-none-any.whl size=12941 sha256=68bd212dcd1ef73293a0b8bd7e633076d3df8c9dd9d21458c3fe06b26d0994b8\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/b3/67/58/bcfb43b6ab764496a446021a8d05991adffd48c16582381326\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2020.7.14-cp37-cp37m-macosx_10_9_x86_64.whl size=286543 sha256=16b488af30096cb77bafca2ac83fb04c3451bf03c3dbcf7f4ad6fdc1080a54a9\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/5b/68/ce/2508b5a5afc13bd96566c62d3ffebea7b401477c2ead3e8cc0\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=09083c3153452a957c7d8ffe6602538535ec93f20298b33b2f9acb9c1984089d\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-py3-none-any.whl size=7553 sha256=2c1e2d66f7b67e44f20c52f3e326232c987d93c524d7783c32f54b81826d19e1\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/65/66/e9/c7eafddc29b81a98786f12b48a2aee7e3c633f6bf4a62cbc20\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-py3-none-any.whl size=15613 sha256=a37bc269eb99376aa324c3b1cd0aca2d859a109cb1ace599330d59a0d8755b4e\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/21/38/cc/50e6d62d6d458e8223d3ddaef7c622b67ae57708193918051b\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-py3-none-any.whl size=5267 sha256=068159b7b6e3977eaac61c076f986d8da0b7e1f27392de6e45885f63de770fd6\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/58/14/24/76b0d99b7d9cc17e110956e0fae825a5da3e70a60273220502\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-py3-none-any.whl size=5623 sha256=3e5393bbab232bb7f9a1b6309b3df77233308fc3313109d6c229d6c82fce6e79\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/9e/53/a2/651c985b605e6a6c48688c779808eb1956fabb910b0557d871\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-py3-none-any.whl size=4558 sha256=9e8623ef80eb7e2e47e3ed36e2a1b3e14dee783fa25f8aa5e65ca324d9fff450\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/2d/31/2c/2d3fb4442f6112b92cd56bf801ff25421f302c755f935d4a79\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=81c25e31a502790fc192c241e72459db211c8bf59e48f41d3173d09c4be5ef7a\n",
      "  Stored in directory: /Users/mv96/Library/Caches/pip/wheels/ec/f7/48/30de93f8333298bad9202aab9b04db0cfd58dcd379b5a5ef1c\n",
      "Successfully built ktrain keras-bert langdetect jieba cchardet seqeval syntok shap keras-transformer regex sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow, scikit-learn, fastprogress, Keras, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, jieba, cchardet, seqeval, tokenizers, regex, sacremoses, sentencepiece, transformers, syntok, whoosh, shap, ktrain\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.1\n",
      "    Uninstalling tensorboard-2.2.1:\n",
      "      Successfully uninstalled tensorboard-2.2.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "Successfully installed Keras-2.4.3 cchardet-2.1.5 fastprogress-0.2.5 gast-0.2.2 jieba-0.42.1 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.19.3 langdetect-1.0.8 regex-2020.7.14 sacremoses-0.0.43 scikit-learn-0.21.3 sentencepiece-0.1.91 seqeval-0.0.12 shap-0.35.0 syntok-1.3.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tokenizers-0.8.1rc1 transformers-3.0.2 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "4ptmgJ1dvEKr",
    "outputId": "cb2e7acf-996b-4c6c-bfe9-8ec60f6e9e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Id', 'ProductId', 'UserId', 'ProfileName',\n",
      "       'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time',\n",
      "       'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "(362168, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  this witty little book makes my son laugh at l...      1\n",
       "1  I grew up reading these Sendak books, and watc...      1\n",
       "2  This is a fun way for children to learn their ...      1\n",
       "3  This is a great little book to read aloud- it ...      1\n",
       "4  This is a book of poetry about the months of t...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews=pd.read_csv(\"/Users/mv96/Desktop/ai/cit/second semester/project- sentiment analysis /afr_unique.csv\")\n",
    "print(reviews.columns)\n",
    "new=reviews[[\"Text\",\"Score\"]]\n",
    "print(new.shape)\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "qKRniaqLwfvO",
    "outputId": "4ca36c0b-6c1f-49d6-fe5a-aa9d6141b82f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I am on the board of an animal shelter, and have 23 cats of my own.  We were directed to Wellness as an excellent no-grain food.  We buy the largest sized cans, and we spend almost $800 per month on this food.  The cats used to love all of the flavors we bought (Turkey, Chx, Chx and Beef, Turkey and Salmon) and suddenly NONE of them will eat ANY of them!  I can only surmise that something has happened to the recipe, or the quality of the ingredients.  It makes no sense.  More bizarre, we feed the outdoor (feral) cats the food and many of them won't touch it, either.  The hunt is on to find the next \"great food\"...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_tr = new[\"Text\"]\n",
    "X_tr = new['Score']\n",
    "\n",
    "# complex sentences\n",
    "print(X_tr[1702])\n",
    "print(y_tr[1702])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyQHsFmn7vcC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "XJAZL8nONrQi",
    "outputId": "7e49f276-1fe5-451d-a2f7-1cb978ade1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== train data (80%)====================\n",
      "(289734, 2)\n",
      "==================== test data (20%)====================\n",
      "(72434, 2)\n"
     ]
    }
   ],
   "source": [
    "#train test split and random splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create training and testing data (80% train and 20% test)\n",
    "data_train, data_test = train_test_split(new,test_size=0.2,random_state=5)#test size here relates to second var i.e test\n",
    "\n",
    "print(\"=\"*20+\" train data (80%)\"+\"=\"*20)\n",
    "print (data_train.shape)\n",
    "print(\"=\"*20+\" test data (20%)\"+\"=\"*20)\n",
    "print (data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "G0JXJMRMea5u",
    "outputId": "6fb73ca6-4761-48ac-da55-f8f33b1ad9c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
     ]
    }
   ],
   "source": [
    "#activate tpu\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "9PEkmGdEl29t",
    "outputId": "cc5f5ea5-fd4d-4da6-d3bd-a9b42c4de5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#with strategy.scope():\n",
    "(X_train,y_train),(X_test,y_test), preprocess=text.texts_from_df(train_df=data_train,\n",
    "                   text_column=\"Text\",\n",
    "                   label_columns=\"Score\",\n",
    "                   val_df=data_test,\n",
    "                   maxlen=400,\n",
    "                   preprocess_mode=\"bert\")\n",
    "\n",
    "#if reviews are less than 400 the reviews are padded otherwise they are truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WrjcBWOj9sfC",
    "outputId": "67d2692c-7d41-429c-c115-63a1de4e0dcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289734, 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "TlkLjofD-GXp",
    "outputId": "82b10358-57f4-4733-f2a5-198660c4ffcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 400\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "#initialize the model\n",
    "with strategy.scope():\n",
    "  model=text.text_classifier(name=\"bert\",\n",
    "                           train_data=(X_train,y_train),\n",
    "                           preproc=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMNvm-KDl-Wx"
   },
   "outputs": [],
   "source": [
    "#define the learning rate\n",
    "#but the bert can find optimal learning rate\n",
    "with strategy.scope():\n",
    "  learner=ktrain.get_learner(model=model,\n",
    "                           train_data=(X_train,y_train),\n",
    "                           val_data=(X_test,y_test),\n",
    "                           batch_size=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vCiYRNJ_ku5"
   },
   "outputs": [],
   "source": [
    "#find the optimal learning rate\n",
    "#can take much long time to run\n",
    "\n",
    "#learner.lr_find()\n",
    "#learner.lr_plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "E5MrKObu_sJV",
    "outputId": "2415dd30-f10e-4529-f2aa-abc7403e3e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Train on 289734 samples, validate on 72434 samples\n",
      "289734/289734 [==============================] - 7220s 25ms/sample - loss: 0.0276 - accuracy: 0.9873 - val_loss: 0.0647 - val_accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "#with gpu's it takes 16hrs for 2 epochs with tpu's it takes 2hrs for 2 epochs\n",
    "\n",
    "#already fitted the first epoch\n",
    "with strategy.scope():\n",
    "  learner.fit_onecycle(lr=2e-5,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVic15PDHQoX"
   },
   "outputs": [],
   "source": [
    "predictor=ktrain.get_predictor(learner.model,preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0nOvFXLDSP9"
   },
   "outputs": [],
   "source": [
    " predictor.save(\"/content/drive/My Drive/bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "predictor = ktrain.load_predictor('/Users/mv96/Downloads/bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LaqoUJjAm7_z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42066014 0.57933986]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"you stopped saying goodnight and stopped sleeping\"\n",
    "data=[text]\n",
    "print(predictor.predict_proba(data))\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ktrain.text.predictor.TextPredictor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(predictor))\n",
    "print(predictor.analyze_valid((X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
